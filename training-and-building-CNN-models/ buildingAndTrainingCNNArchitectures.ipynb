{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iXEUxZsLEwpk"
   },
   "source": [
    "# Building and training the CNN architectures\n",
    "This notebook aims to build and train each CNN architecture used in the experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "agDKqr0PLHOf"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from keras import models\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tqdm import trange\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import seaborn as sns \n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "import cv2\n",
    "from keras.preprocessing import image\n",
    "from os import listdir\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from os.path import isfile, join\n",
    "from tensorflow.keras import layers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iowjF6y_F5Mq"
   },
   "source": [
    "## Building the popular CNN architectures\n",
    "\n",
    "#### Popular CNN models:\n",
    "1.  Xception\n",
    "2.  VGG16\n",
    "3.  VGG19\n",
    "4.  ResNet50\n",
    "5.  ResNet50V2\n",
    "6.  ResNet101\n",
    "7.  ResNet101V2\n",
    "8.  ResNet152V2\n",
    "9.  InceptionResNetV2\n",
    "10. DenseNet121\n",
    "11. DenseNet169\n",
    "12. NASNetMobile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ePItzfn2SVmX"
   },
   "outputs": [],
   "source": [
    "#Please add the name of CNN architecture you want to import\n",
    "#from tensorflow.keras.applications import [EfficientNetV2B0]\n",
    "\n",
    "from tensorflow.keras.applications import EfficientNetV2B0\n",
    "\n",
    "def get_model():\n",
    " \n",
    "  img_rows, img_cols = 224,224\n",
    "  model = Sequential()\n",
    "#Change the name of CNN architecture\n",
    " #model = [EfficientNetV2B0](weights='imagenet', include_top = False,  input_shape = (img_rows, img_cols, 3))\n",
    "  model = EfficientNetV2B0(weights='imagenet', include_top = False,  input_shape = (img_rows, img_cols, 3))\n",
    "\n",
    "  #Features Learning\n",
    "  for layer in model.layers:\n",
    "    layer.trainable = True\n",
    "    \n",
    "  #Classification part\n",
    "  top_model =model.output\n",
    "  top_model = GlobalAveragePooling2D()(top_model)\n",
    "  output = Dense(1,activation='sigmoid')(top_model)\n",
    "  \n",
    "  model = Model(inputs = model.input, outputs = output)\n",
    "\n",
    "  model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "  \n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4645,
     "status": "ok",
     "timestamp": 1669363409409,
     "user": {
      "displayName": "Ahmed Alia",
      "userId": "11152060568798647618"
     },
     "user_tz": -60
    },
    "id": "qycZifSDafLy",
    "outputId": "3d13675f-a6ff-4d7b-c221-0a9466c1e46d"
   },
   "outputs": [],
   "source": [
    "model = get_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mLGBTX9jHiWi"
   },
   "source": [
    "### Loading the training and validation sets, then training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eCVM6b9eaSl0"
   },
   "outputs": [],
   "source": [
    "#type the path of training and validation sets\n",
    "train_data_dir = \"Path of the training set\"\n",
    "validation_data_dir = \"Path of the validation set\"\n",
    " \n",
    "train_datagen = ImageDataGenerator()\n",
    "validation_datagen = ImageDataGenerator()\n",
    " \n",
    "epochs=100\n",
    "batch_size = 32\n",
    "img_rows, img_cols=224,224 \n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "          train_data_dir,\n",
    "          target_size=(img_rows, img_cols),\n",
    "          batch_size=batch_size,\n",
    "          class_mode='binary')\n",
    "  \n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "          validation_data_dir,\n",
    "          target_size=(img_rows, img_cols),\n",
    "          batch_size=batch_size,\n",
    "          class_mode='binary')\n",
    "  \n",
    "  ###################################\n",
    "x=\"Name of the generated model\"\n",
    "  ###################################\n",
    "filepath =  'The path of the directory that will contain the generated model/'+x+'.h5'\n",
    "#filepath =  home_path+'TLmodels/'+x+'-epoch{epoch:02d}-acc{val_accuracy:.2f}.h5'\n",
    "  #filepath =  home_path+'models/'+x+'/'+str(f)+'.h5'\n",
    "checkpoint = ModelCheckpoint(filepath ,\n",
    "                             monitor=\"val_accuracy\",\n",
    "                             mode=\"max\",\n",
    "                             save_best_only = True,\n",
    "                             verbose=1)\n",
    " \n",
    "earlystop = EarlyStopping(monitor = 'val_accuracy', \n",
    "                          min_delta = 0, \n",
    "                          patience = 20,\n",
    "                          verbose = 1,\n",
    "                          restore_best_weights = True\n",
    "                          )\n",
    "callbacks = [earlystop, checkpoint]\n",
    " \n",
    "# Fit data to model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs = epochs,\n",
    "    callbacks = callbacks,\n",
    "    batch_size =batch_size,\n",
    "    validation_data = validation_generator,\n",
    "    shuffle=True\n",
    "    \n",
    "    )\n",
    "   \n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2_CZ0D8QJn-F"
   },
   "source": [
    "## CNN architictures in the related works"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "36tF69yAJ4jk"
   },
   "source": [
    "### CNN-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mH7ch3jXKDid"
   },
   "source": [
    "#### The architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TbkrwA8bKArj"
   },
   "outputs": [],
   "source": [
    "img_rows = 75\n",
    "img_cols = 75\n",
    "input_shape = (img_rows, img_cols, 3)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(8, (5, 5), input_shape=input_shape))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "\n",
    "model.add(Conv2D(16, (3, 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('Softmax'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "  \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QP2p0HfvN3cH"
   },
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KFNdeuSBOJRg"
   },
   "outputs": [],
   "source": [
    "#Type the path of training and validation sets\n",
    "train_data_dir = \"Path of the training set\"\n",
    "validation_data_dir = \"Path of the validation set\"\n",
    " \n",
    "train_datagen = ImageDataGenerator()\n",
    "validation_datagen = ImageDataGenerator()\n",
    " \n",
    "epochs=100\n",
    "batch_size = 32\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "          train_data_dir,\n",
    "          target_size=(img_rows, img_cols),\n",
    "          batch_size=batch_size,\n",
    "          class_mode='binary')\n",
    "  \n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "          validation_data_dir,\n",
    "          target_size=(img_rows, img_cols),\n",
    "          batch_size=batch_size,\n",
    "          class_mode='binary')\n",
    "  \n",
    "  ###################################\n",
    "x=\"Name of the generated model\"\n",
    "  ###################################\n",
    "filepath =  'The path of the directory that will contain the generated model/'+x+'.h5'\n",
    "#filepath =  home_path+'TLmodels/'+x+'-epoch{epoch:02d}-acc{val_accuracy:.2f}.h5'\n",
    "  #filepath =  home_path+'models/'+x+'/'+str(f)+'.h5'\n",
    "checkpoint = ModelCheckpoint(filepath ,\n",
    "                             monitor=\"val_accuracy\",\n",
    "                             mode=\"max\",\n",
    "                             save_best_only = True,\n",
    "                             verbose=1)\n",
    " \n",
    "earlystop = EarlyStopping(monitor = 'val_accuracy', \n",
    "                          min_delta = 0, \n",
    "                          patience = 20,\n",
    "                          verbose = 1,\n",
    "                          restore_best_weights = True\n",
    "                          )\n",
    "callbacks = [earlystop, checkpoint]\n",
    " \n",
    "# Fit data to model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs = epochs,\n",
    "    callbacks = callbacks,\n",
    "    batch_size =batch_size,\n",
    "    validation_data = validation_generator,\n",
    "    shuffle=True\n",
    "    \n",
    "    )\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nLiLooZYOb9Z"
   },
   "source": [
    "### CNN-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-KrzgsXNOiAv"
   },
   "source": [
    "#### The architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CWYQ-tk7Onzs"
   },
   "outputs": [],
   "source": [
    "img_rows = 32\n",
    "img_cols = 32\n",
    "input_shape = (img_rows, img_cols, 3)\n",
    "\n",
    "model = Sequential()\n",
    "#model.add(tf.layers.ZeroPadding2D(padding=(2, 2)))\n",
    "model.add(Conv2D(32, (5, 5), padding='same', input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (5, 5), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (5, 5), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('Softmax'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "  \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9YEcpX02OwCG"
   },
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nKzX62dbO0Rq"
   },
   "outputs": [],
   "source": [
    "#Type the path of training and validation sets\n",
    "train_data_dir = \"Path of the training set\"\n",
    "validation_data_dir = \"Path of the validation set\"\n",
    " \n",
    "train_datagen = ImageDataGenerator()\n",
    "validation_datagen = ImageDataGenerator()\n",
    " \n",
    "epochs=100\n",
    "batch_size = 32\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "          train_data_dir,\n",
    "          target_size=(img_rows, img_cols),\n",
    "          batch_size=batch_size,\n",
    "          class_mode='binary')\n",
    "  \n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "          validation_data_dir,\n",
    "          target_size=(img_rows, img_cols),\n",
    "          batch_size=batch_size,\n",
    "          class_mode='binary')\n",
    "  \n",
    "  ###################################\n",
    "x=\"Name of the generated model\"\n",
    "  ###################################\n",
    "filepath =  'The path of the directory that will contain the generated model/'+x+'.h5'\n",
    "#filepath =  home_path+'TLmodels/'+x+'-epoch{epoch:02d}-acc{val_accuracy:.2f}.h5'\n",
    "  #filepath =  home_path+'models/'+x+'/'+str(f)+'.h5'\n",
    "checkpoint = ModelCheckpoint(filepath ,\n",
    "                             monitor=\"val_accuracy\",\n",
    "                             mode=\"max\",\n",
    "                             save_best_only = True,\n",
    "                             verbose=1)\n",
    " \n",
    "earlystop = EarlyStopping(monitor = 'val_accuracy', \n",
    "                          min_delta = 0, \n",
    "                          patience = 20,\n",
    "                          verbose = 1,\n",
    "                          restore_best_weights = True\n",
    "                          )\n",
    "callbacks = [earlystop, checkpoint]\n",
    " \n",
    "# Fit data to model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs = epochs,\n",
    "    callbacks = callbacks,\n",
    "    batch_size =batch_size,\n",
    "    validation_data = validation_generator,\n",
    "    shuffle=True\n",
    "    \n",
    "    )\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hzyXJ2DCO4ku"
   },
   "source": [
    "### Adapted EfficientNetV1B0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h9svtvPyPBCO"
   },
   "source": [
    "#### The architicture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ei6v1dl4PD-k"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "img_rows, img_cols = 224,224\n",
    "model = Sequential()\n",
    "model = EfficientNetB0(weights='imagenet', include_top = False,  input_shape = (img_rows, img_cols, 3))\n",
    "  #Features Learning\n",
    "for layer in model.layers:\n",
    "    layer.trainable = True    \n",
    "  #Classification part\n",
    "top_model =model.output\n",
    "top_model = GlobalAveragePooling2D()(top_model)\n",
    "output = Dense(1,activation='sigmoid')(top_model)  \n",
    "model = Model(inputs = model.input, outputs = output)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "  \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YLklJRHLPWDo"
   },
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0z1dQm-kPZAd"
   },
   "outputs": [],
   "source": [
    "#Type the path of training and validation sets\n",
    "train_data_dir = \"Path of the training set\"\n",
    "validation_data_dir = \"Path of the validation set\"\n",
    " \n",
    "train_datagen = ImageDataGenerator()\n",
    "validation_datagen = ImageDataGenerator()\n",
    " \n",
    "epochs=100\n",
    "batch_size = 32\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "          train_data_dir,\n",
    "          target_size=(img_rows, img_cols),\n",
    "          batch_size=batch_size,\n",
    "          class_mode='binary')\n",
    "  \n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "          validation_data_dir,\n",
    "          target_size=(img_rows, img_cols),\n",
    "          batch_size=batch_size,\n",
    "          class_mode='binary')\n",
    "  \n",
    "  ###################################\n",
    "x=\"Name of the generated model\"\n",
    "  ###################################\n",
    "filepath =  'The path of the directory that will contain the generated model/'+x+'.h5'\n",
    "#filepath =  home_path+'TLmodels/'+x+'-epoch{epoch:02d}-acc{val_accuracy:.2f}.h5'\n",
    "  #filepath =  home_path+'models/'+x+'/'+str(f)+'.h5'\n",
    "checkpoint = ModelCheckpoint(filepath ,\n",
    "                             monitor=\"val_accuracy\",\n",
    "                             mode=\"max\",\n",
    "                             save_best_only = True,\n",
    "                             verbose=1)\n",
    " \n",
    "earlystop = EarlyStopping(monitor = 'val_accuracy', \n",
    "                          min_delta = 0, \n",
    "                          patience = 20,\n",
    "                          verbose = 1,\n",
    "                          restore_best_weights = True\n",
    "                          )\n",
    "callbacks = [earlystop, checkpoint]\n",
    " \n",
    "# Fit data to model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs = epochs,\n",
    "    callbacks = callbacks,\n",
    "    batch_size =batch_size,\n",
    "    validation_data = validation_generator,\n",
    "    shuffle=True\n",
    "    \n",
    "    )\n",
    "   "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
